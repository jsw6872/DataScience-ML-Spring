{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:[1.12.1+cu113].\n",
      "device:[cuda:0].\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "print('PyTorch version:[%s].'%(torch.__version__))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:[%s].'%(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f0b97109c342578c40b291b4212ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d20b35fda94c25817431e94b82fa45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fcbf43a4434405bb3d198de94d2975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548a35e3d506415b809bae2763379cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "mnist_train = datasets.MNIST(root='./data/', train = True, transform = transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root='./data/', train = False, transform = transforms.ToTensor(), download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_train:\n",
      " Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data/\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor() \n",
      "\n",
      "mnist_test:\n",
      " Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data/\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor() \n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('mnist_train:\\n', mnist_train, '\\n')\n",
    "print('mnist_test:\\n', mnist_test, '\\n')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train, batch_size = BATCH_SIZE, shuffle=True, num_workers=1)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test, batch_size = BATCH_SIZE, shuffle=True, num_workers=1)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptronClass(nn.Module):\n",
    "    def __init__(self, name='mlp', xdim=784, hdim=256, ydim = 10):\n",
    "        super(MultiLayerPerceptronClass,self).__init__()\n",
    "        self.name = name\n",
    "        self.xdim = xdim # input layer\n",
    "        self.hdim = hdim # hidden layer\n",
    "        self.ydim = ydim # output layer\n",
    "        self.lin_1 = nn.Linear(self.xdim, self.hdim)\n",
    "        self.lin_2 = nn.Linear(self.hdim, self.ydim)\n",
    "        self.init_param()\n",
    "\n",
    "    def init_param(self):\n",
    "        nn.init.kaiming_normal_(self.lin_1.weight)\n",
    "        nn.init.zeros_(self.lin_1.bias)\n",
    "        nn.init.kaiming_normal_(self.lin_2.weight)\n",
    "        nn.init.zeros_(self.lin_2.bias)\n",
    "    \n",
    "\n",
    "    def forward(self,x):\n",
    "        net = x\n",
    "        net = self.lin_1(net)\n",
    "        net = F.relu(net)\n",
    "        net = self.lin_2(net)\n",
    "        return net\n",
    "M = MultiLayerPerceptronClass(name='mlp', xdim = 784, hdim = 256, ydim = 10).to(device) # 사용하는 cpu or gpu로 넘겨줌\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optm = optim.Adam(M.parameters(), lr = 1e-3)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_numpy = np.random.rand(2,784)\n",
    "x_torch = torch.from_numpy(x_numpy).float().to(device)\n",
    "y_torch = M.forward(x_torch)\n",
    "y_numpy = y_torch.detach().cpu().numpy()\n",
    "\n",
    "print('x_numpy:\\n', x_numpy)\n",
    "print('x_torch:\\n', x_torch)\n",
    "print('y_torch:\\n', y_torch)\n",
    "print('y_numpy:\\n', y_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "n_param = 0\n",
    "for p_idx, (param_name, param) in enumerate(M.named_parameters()):\n",
    "    param_numpy = param.detach().cpu().numpy()\n",
    "    n_param += len(param_numpy.reshape(-1))\n",
    "    print('[%d] name:[%s].'%(p_idx,param_name, param_numpy.shape))\n",
    "    print('      val%s'%(param_numpy.reshape(-1)[:5]))\n",
    "print('Total number of parameters:[%s].'%(format(n_param,'d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_eval(model, data_iter, device):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        n_total, n_correct = 0, 0\n",
    "        for batch_in, batch_out in data_iter:\n",
    "            y_trgt = batch_out.to(device)\n",
    "            model_pred = model(batch_in.view())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('da')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "451282c7329e2a6a364ca3aa9d61cbc27edaeb5d17f404c45e9cca05e3b54b52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
